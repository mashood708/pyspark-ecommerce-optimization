{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#üöÄ Step 1: Set Up Spark Session\n",
        "\n"
      ],
      "metadata": {
        "id": "-tJETMtZD0H2"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "idctOM93Dftx"
      },
      "outputs": [],
      "source": [
        "from pyspark.sql import SparkSession\n",
        "\n",
        "spark = SparkSession.builder.appName(\"PySparkOptimizationProject\").getOrCreate()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#üöÄ Step 2: Simulate Large Transaction Data\n"
      ],
      "metadata": {
        "id": "4qZPXv4REMq9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# small transaction data\n",
        "transactions = [\n",
        "    (1, \"user_1\", \"product_1\", 100),\n",
        "    (2, \"user_2\", \"product_2\", 150),\n",
        "    (3, \"user_3\", \"product_3\", 120),\n",
        "]\n",
        "columns = [\"transaction_id\", \"user_id\", \"product_id\", \"amount\"]\n",
        "\n",
        "small_tx_df = spark.createDataFrame(transactions, columns)\n",
        "\n",
        "# expand 15 times (2^15 ‚âà 32k rows)\n",
        "large_tx_df = small_tx_df\n",
        "for _ in range(15):\n",
        "    large_tx_df = large_tx_df.union(small_tx_df)\n",
        "\n",
        "print(f\"Total transaction rows: {large_tx_df.count()}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w03fSmGhETrA",
        "outputId": "3af7b50f-9bfc-4486-c82a-96b4fdc45974"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total transaction rows: 48\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "large_tx_df.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hsn5loACEfDK",
        "outputId": "7c10b6b9-b715-4f29-be4f-49aae04fa3e1"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------------+-------+----------+------+\n",
            "|transaction_id|user_id|product_id|amount|\n",
            "+--------------+-------+----------+------+\n",
            "|             1| user_1| product_1|   100|\n",
            "|             2| user_2| product_2|   150|\n",
            "|             3| user_3| product_3|   120|\n",
            "|             1| user_1| product_1|   100|\n",
            "|             2| user_2| product_2|   150|\n",
            "|             3| user_3| product_3|   120|\n",
            "|             1| user_1| product_1|   100|\n",
            "|             2| user_2| product_2|   150|\n",
            "|             3| user_3| product_3|   120|\n",
            "|             1| user_1| product_1|   100|\n",
            "|             2| user_2| product_2|   150|\n",
            "|             3| user_3| product_3|   120|\n",
            "|             1| user_1| product_1|   100|\n",
            "|             2| user_2| product_2|   150|\n",
            "|             3| user_3| product_3|   120|\n",
            "|             1| user_1| product_1|   100|\n",
            "|             2| user_2| product_2|   150|\n",
            "|             3| user_3| product_3|   120|\n",
            "|             1| user_1| product_1|   100|\n",
            "|             2| user_2| product_2|   150|\n",
            "+--------------+-------+----------+------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#üöÄ Step 3: Create Product Catalog (Lookup Table)\n",
        "\n"
      ],
      "metadata": {
        "id": "HZp1ZKPuFLOF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "product_catalog = [\n",
        "    (\"product_1\", \"Electronics\", 250),\n",
        "    (\"product_2\", \"Clothing\", 80),\n",
        "    (\"product_3\", \"Groceries\", 30),\n",
        "]\n",
        "product_columns = [\"product_id\", \"category\", \"unit_price\"]\n",
        "\n",
        "product_df = spark.createDataFrame(product_catalog, product_columns)\n",
        "product_df.show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y1zrL5C4FQCp",
        "outputId": "79eb9e06-d097-48fe-aa94-f74d3b9f1a20"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----------+-----------+----------+\n",
            "|product_id|   category|unit_price|\n",
            "+----------+-----------+----------+\n",
            "| product_1|Electronics|       250|\n",
            "| product_2|   Clothing|        80|\n",
            "| product_3|  Groceries|        30|\n",
            "+----------+-----------+----------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#üöÄ Step 4: Join Transaction with Product Data\n"
      ],
      "metadata": {
        "id": "dSob60EpFlZm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "joined_df_shuffle = large_tx_df.join(product_df, on=\"product_id\", how=\"left\")\n",
        "joined_df_shuffle.show(5)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KWNX4VAPFp7f",
        "outputId": "f2233915-73f1-4b1c-aaec-88d62f25bd46"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----------+--------------+-------+------+-----------+----------+\n",
            "|product_id|transaction_id|user_id|amount|   category|unit_price|\n",
            "+----------+--------------+-------+------+-----------+----------+\n",
            "| product_1|             1| user_1|   100|Electronics|       250|\n",
            "| product_3|             3| user_3|   120|  Groceries|        30|\n",
            "| product_2|             2| user_2|   150|   Clothing|        80|\n",
            "| product_1|             1| user_1|   100|Electronics|       250|\n",
            "| product_3|             3| user_3|   120|  Groceries|        30|\n",
            "+----------+--------------+-------+------+-----------+----------+\n",
            "only showing top 5 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#üöÄ Step 5: Broadcast Join\n"
      ],
      "metadata": {
        "id": "ERuXk84-F5tC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql.functions import broadcast\n",
        "\n",
        "joined_df_broadcast = large_tx_df.join(broadcast(product_df), on=\"product_id\", how=\"left\")\n",
        "\n",
        "joined_df_broadcast.show(5)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WHDEoWCLF8dX",
        "outputId": "37971e6e-e9eb-49c3-9c06-3b557dea16ab"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----------+--------------+-------+------+-----------+----------+\n",
            "|product_id|transaction_id|user_id|amount|   category|unit_price|\n",
            "+----------+--------------+-------+------+-----------+----------+\n",
            "| product_1|             1| user_1|   100|Electronics|       250|\n",
            "| product_2|             2| user_2|   150|   Clothing|        80|\n",
            "| product_3|             3| user_3|   120|  Groceries|        30|\n",
            "| product_1|             1| user_1|   100|Electronics|       250|\n",
            "| product_2|             2| user_2|   150|   Clothing|        80|\n",
            "+----------+--------------+-------+------+-----------+----------+\n",
            "only showing top 5 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#‚è± Profile performance\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "Bw9y22T9GGle"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "\n",
        "start = time.time()\n",
        "joined_df_broadcast.count()\n",
        "print(\"Broadcast join time: \", time.time() - start)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q9bs-bzBGNUL",
        "outputId": "94feabbd-967a-483f-fe1d-d575b663dcdf"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Broadcast join time:  6.003990650177002\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#üöÄ Step 6: Repartition\n"
      ],
      "metadata": {
        "id": "bB9PdOo-GUDo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Partitions before:\", large_tx_df.rdd.getNumPartitions())\n",
        "\n",
        "repartitioned_df = joined_df_broadcast.repartition(16)\n",
        "print(\"Partitions after repartition:\", repartitioned_df.rdd.getNumPartitions())\n",
        "\n",
        "# simulate write\n",
        "repartitioned_df.write.mode(\"overwrite\").parquet(\"/tmp/tx_repartitioned\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9ytZFoXmGYME",
        "outputId": "72352083-db25-4e00-a2f1-a6fc29dff5b2"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Partitions before: 32\n",
            "Partitions after repartition: 16\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#üöÄ Step 7: Coalesce\n"
      ],
      "metadata": {
        "id": "oZB0DuisGnGs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "coalesced_df = repartitioned_df.coalesce(4)\n",
        "print(\"Partitions after coalesce:\", coalesced_df.rdd.getNumPartitions())\n",
        "\n",
        "coalesced_df.write.mode(\"overwrite\").parquet(\"/tmp/tx_coalesced\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xy8Eip6oGp46",
        "outputId": "314b2c8b-766e-4df2-d08a-6ee3fb3d585d"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Partitions after coalesce: 4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#üöÄ Step 8: Caching and Persist\n"
      ],
      "metadata": {
        "id": "Lkkgvx3BG2Zm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# using cache\n",
        "cached_df = joined_df_broadcast.cache()\n",
        "cached_df.count()  # triggers caching\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tHWao9EqreCe",
        "outputId": "de70df37-a897-473a-fafb-d0c85f164773"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "48"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "# using persist with MEMORY_AND_DISK\n",
        "from pyspark import StorageLevel\n",
        "persisted_df = joined_df_broadcast.persist(StorageLevel.MEMORY_AND_DISK)\n",
        "persisted_df.count()  # triggers persist\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Rrvp4-lVG8Ti",
        "outputId": "eb453472-7c27-44ea-e18b-8ffc057225c6"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "48"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#‚è± Profile performance:\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "4Vp61xYpHCKf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "start = time.time()\n",
        "cached_df.count()\n",
        "print(\"Count after cache: \", time.time() - start)\n",
        "\n",
        "start = time.time()\n",
        "persisted_df.count()\n",
        "print(\"Count after persist: \", time.time() - start)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ib4-NVHDHIxX",
        "outputId": "9b509d71-a319-4df5-f9a5-ced7a0e22ddf"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Count after cache:  1.0293893814086914\n",
            "Count after persist:  1.1298937797546387\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#üöÄ Step 9: Catalyst Optimizer Demonstration\n"
      ],
      "metadata": {
        "id": "kKgHpKdQHR2f"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# hint for broadcast\n",
        "hinted_df = large_tx_df.join(\n",
        "    product_df.hint(\"broadcast\"), on=\"product_id\", how=\"left\"\n",
        ")\n",
        "hinted_df.explain()  # shows Catalyst logical & physical plan\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PsohDfptHUUK",
        "outputId": "27790c28-270d-452f-8d7f-3c935f50a2c6"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "== Physical Plan ==\n",
            "AdaptiveSparkPlan isFinalPlan=false\n",
            "+- InMemoryTableScan [product_id#235, transaction_id#233L, user_id#234, amount#236L, category#448, unit_price#449L]\n",
            "      +- InMemoryRelation [product_id#235, transaction_id#233L, user_id#234, amount#236L, category#448, unit_price#449L], StorageLevel(disk, memory, deserialized, 1 replicas)\n",
            "            +- AdaptiveSparkPlan isFinalPlan=false\n",
            "               +- Project [product_id#235, transaction_id#233L, user_id#234, amount#236L, category#448, unit_price#449L]\n",
            "                  +- BroadcastHashJoin [product_id#235], [product_id#447], LeftOuter, BuildRight, false\n",
            "                     :- Union\n",
            "                     :  :- Scan ExistingRDD[transaction_id#233L,user_id#234,product_id#235,amount#236L]\n",
            "                     :  :- Scan ExistingRDD[transaction_id#241L,user_id#242,product_id#243,amount#244L]\n",
            "                     :  :- Scan ExistingRDD[transaction_id#249L,user_id#250,product_id#251,amount#252L]\n",
            "                     :  :- Scan ExistingRDD[transaction_id#257L,user_id#258,product_id#259,amount#260L]\n",
            "                     :  :- Scan ExistingRDD[transaction_id#265L,user_id#266,product_id#267,amount#268L]\n",
            "                     :  :- Scan ExistingRDD[transaction_id#273L,user_id#274,product_id#275,amount#276L]\n",
            "                     :  :- Scan ExistingRDD[transaction_id#281L,user_id#282,product_id#283,amount#284L]\n",
            "                     :  :- Scan ExistingRDD[transaction_id#289L,user_id#290,product_id#291,amount#292L]\n",
            "                     :  :- Scan ExistingRDD[transaction_id#297L,user_id#298,product_id#299,amount#300L]\n",
            "                     :  :- Scan ExistingRDD[transaction_id#305L,user_id#306,product_id#307,amount#308L]\n",
            "                     :  :- Scan ExistingRDD[transaction_id#313L,user_id#314,product_id#315,amount#316L]\n",
            "                     :  :- Scan ExistingRDD[transaction_id#321L,user_id#322,product_id#323,amount#324L]\n",
            "                     :  :- Scan ExistingRDD[transaction_id#329L,user_id#330,product_id#331,amount#332L]\n",
            "                     :  :- Scan ExistingRDD[transaction_id#337L,user_id#338,product_id#339,amount#340L]\n",
            "                     :  :- Scan ExistingRDD[transaction_id#345L,user_id#346,product_id#347,amount#348L]\n",
            "                     :  +- Scan ExistingRDD[transaction_id#353L,user_id#354,product_id#355,amount#356L]\n",
            "                     +- BroadcastExchange HashedRelationBroadcastMode(List(input[0, string, false]),false), [plan_id=3501]\n",
            "                        +- Filter isnotnull(product_id#447)\n",
            "                           +- Scan ExistingRDD[product_id#447,category#448,unit_price#449L]\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#üöÄ Step 10: Final Profiling\n"
      ],
      "metadata": {
        "id": "11zNJAMKHju3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# shuffle join baseline\n",
        "start = time.time()\n",
        "joined_df_shuffle.count()\n",
        "print(\"Shuffle join count time:\", time.time() - start)\n",
        "\n",
        "# broadcast join with caching\n",
        "start = time.time()\n",
        "cached_df.count()\n",
        "print(\"Broadcast + cache count time:\", time.time() - start)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8FCUSp9THo4M",
        "outputId": "ea1014f6-53dd-4366-8213-e195e3aa1f5c"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shuffle join count time: 0.8022630214691162\n",
            "Broadcast + cache count time: 0.6562621593475342\n"
          ]
        }
      ]
    }
  ]
}